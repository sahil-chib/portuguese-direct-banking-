{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
       "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
       "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
       "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
       "4  unknown    5   may       198         1     -1         0  unknown  no  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(\"C:\\\\Users\\\\abc\\\\Downloads\\\\PRCP-1000-ProtugeseBank\\\\Data\\\\bank-full.csv\",sep=\";\")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age           15.0\n",
      "balance     1356.0\n",
      "day           13.0\n",
      "duration     216.0\n",
      "campaign       2.0\n",
      "pdays          0.0\n",
      "previous       0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "#df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower outlier in duration -221.0\n",
      "upper outlier in duration 643.0\n",
      "number of upper outliers in duration :  3235\n",
      "number of lower outliers in duration :  0\n",
      "percentage of upper outliers in duration :  7.155338302625467 %\n",
      "percentage of lower outliers in duration :  0.0 %\n"
     ]
    }
   ],
   "source": [
    "q1duration=df['duration'].quantile(q=0.25)\n",
    "q3duration=df['duration'].quantile(q=0.75)\n",
    "IQR= q3duration-q1duration\n",
    "l_out= q1duration-1.5*(IQR)\n",
    "u_out= q3duration+1.5*(IQR)\n",
    "print(\"lower outlier in duration\",l_out)\n",
    "print(\"upper outlier in duration\",u_out)\n",
    "upper_duration=df[df['duration']>643.0]['duration'].count()\n",
    "lower_duration=df[df['duration']<-221]['duration'].count()\n",
    "print('number of upper outliers in duration : ', upper_duration )\n",
    "print('number of lower outliers in duration : ', lower_duration )\n",
    "print('percentage of upper outliers in duration : ', upper_duration*100/len(df),'%')\n",
    "print('percentage of lower outliers in duration : ', lower_duration*100/len(df),'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower outlier in age 10.5\n",
      "upper outlier in age 70.5\n",
      "number of upper outliers in age :  487\n",
      "number of lower outliers in age :  0\n",
      "percentage of upper outliers in age :  1.0771714848156422 %\n",
      "percentage of lower outliers in age :  0.0 %\n"
     ]
    }
   ],
   "source": [
    "q1age=df['age'].quantile(q=0.25)\n",
    "q3age=df['age'].quantile(q=0.75)\n",
    "IQR= q3age-q1age\n",
    "l_out_age= q1age-1.5*(IQR)\n",
    "u_out_age= q3age+1.5*(IQR)\n",
    "print(\"lower outlier in age\",l_out_age)\n",
    "print(\"upper outlier in age\",u_out_age)\n",
    "upper_age=df[df['age']>70.5]['age'].count()\n",
    "lower_age=df[df['age']<-10.5]['age'].count()\n",
    "print('number of upper outliers in age : ', upper_age )\n",
    "print('number of lower outliers in age : ', lower_age )\n",
    "print('percentage of upper outliers in age : ', upper_age*100/len(df),'%')\n",
    "print('percentage of lower outliers in age : ', lower_age*100/len(df),'%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower outlier in bal -1962.0\n",
      "upper outlier in bal 3462.0\n",
      "number of upper outliers in bal :  4712\n",
      "number of lower outliers in bal :  17\n",
      "percentage of upper outliers in bal :  10.42224237464334 %\n",
      "percentage of lower outliers in bal :  0.037601468669129195 %\n"
     ]
    }
   ],
   "source": [
    "q1bal=df['balance'].quantile(q=0.25)\n",
    "q3bal=df['balance'].quantile(q=0.75)\n",
    "IQR= q3bal-q1bal\n",
    "l_out= q1bal-1.5*(IQR)\n",
    "u_out= q3bal+1.5*(IQR)\n",
    "print(\"lower outlier in bal\",l_out)\n",
    "print(\"upper outlier in bal\",u_out)\n",
    "upper_bal=df[df['balance']>3462.0]['balance'].count()\n",
    "lower_bal=df[df['balance']<-1962.0]['balance'].count()\n",
    "print('number of upper outliers in bal : ', upper_bal )\n",
    "print('number of lower outliers in bal : ', lower_bal )\n",
    "print('percentage of upper outliers in bal : ', upper_bal*100/len(df),'%')\n",
    "print('percentage of lower outliers in bal : ', lower_bal*100/len(df),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower outlier in campaign -2.0\n",
      "upper outlier in campaign 6.0\n",
      "number of upper outliers in campaign :  3064\n",
      "number of lower outliers in campaign :  0\n",
      "percentage of upper outliers in campaign :  6.7771117648359915 %\n",
      "percentage of lower outliers in campaign :  0.0 %\n"
     ]
    }
   ],
   "source": [
    "q1cam=df['campaign'].quantile(q=0.25)\n",
    "q3cam=df['campaign'].quantile(q=0.75)\n",
    "IQR= q3cam-q1cam\n",
    "l_out_camp= q1cam-1.5*(IQR)\n",
    "u_out_camp= q3cam+1.5*(IQR)\n",
    "print(\"lower outlier in campaign\",l_out_camp)\n",
    "print(\"upper outlier in campaign\",u_out_camp)\n",
    "upper_cam=df[df['campaign']>6.0]['campaign'].count()\n",
    "lower_cam=df[df['campaign']<-2.0]['campaign'].count()\n",
    "print('number of upper outliers in campaign : ', upper_cam )\n",
    "print('number of lower outliers in campaign : ', lower_cam )\n",
    "print('percentage of upper outliers in campaign : ', upper_cam*100/len(df),'%')\n",
    "print('percentage of lower outliers in campaign : ', lower_cam*100/len(df),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower outlier in pdays -1.0\n",
      "upper outlier in pdays -1.0\n",
      "number of upper outliers in pdays :  8257\n",
      "number of lower outliers in pdays :  0\n",
      "percentage of upper outliers in pdays :  18.263254517705867 %\n",
      "percentage of lower outliers in pdays  :  0.0 %\n"
     ]
    }
   ],
   "source": [
    "q1pday=df['pdays'].quantile(q=0.25)\n",
    "q3pday=df['pdays'].quantile(q=0.75)\n",
    "IQR= q3pday-q1pday\n",
    "l_out= q1pday-1.5*(IQR)\n",
    "u_out= q3pday+1.5*(IQR)\n",
    "print(\"lower outlier in pdays\",l_out)\n",
    "print(\"upper outlier in pdays\",u_out)\n",
    "upper_pday=df[df['pdays']>-1.0]['pdays'].count()\n",
    "lower_pday=df[df['pdays']<-1.0]['pdays'].count()\n",
    "print('number of upper outliers in pdays : ', upper_pday )\n",
    "print('number of lower outliers in pdays : ', lower_pday )\n",
    "print('percentage of upper outliers in pdays : ', upper_pday*100/len(df),'%')\n",
    "print('percentage of lower outliers in pdays  : ', lower_pday*100/len(df),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower outlier in previous 0.0\n",
      "upper outlier in previous 0.0\n",
      "number of upper outliers in previous :  8257\n",
      "number of lower outliers in previous :  0\n",
      "percentage of upper outliers in previous :  18.263254517705867 %\n",
      "percentage of lower outliers in previous  :  0.0 %\n"
     ]
    }
   ],
   "source": [
    "q1pre=df['previous'].quantile(q=0.25)\n",
    "q3pre=df['previous'].quantile(q=0.75)\n",
    "IQR= q3pre-q1pre\n",
    "l_out= q1pre-1.5*(IQR)\n",
    "u_out= q3pre+1.5*(IQR)\n",
    "print(\"lower outlier in previous\",l_out)\n",
    "print(\"upper outlier in previous\",u_out)\n",
    "upper_pre=df[df['previous']>0]['previous'].count()\n",
    "lower_pre=df[df['previous']<0]['previous'].count()\n",
    "print('number of upper outliers in previous : ', upper_pre )\n",
    "print('number of lower outliers in previous : ', lower_pre )\n",
    "print('percentage of upper outliers in previous : ', upper_pre*100/len(df),'%')\n",
    "print('percentage of lower outliers in previous  : ', lower_pre*100/len(df),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    45211.000000\n",
       "mean        40.936210\n",
       "std         10.618762\n",
       "min         18.000000\n",
       "25%         33.000000\n",
       "50%         39.000000\n",
       "75%         48.000000\n",
       "max         95.000000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.age.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c191b26888>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.distplot(df.age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "age isn't normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower outlier in age 10.5\n",
      "upper outlier in age 70.5\n"
     ]
    }
   ],
   "source": [
    "print(\"lower outlier in age\",l_out_age)\n",
    "print(\"upper outlier in age\",u_out_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.age:\n",
    "    if i>u_out_age:\n",
    "        df.replace(i,df['age'].median(),inplace=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of upper outliers in age :  0\n",
      "number of lower outliers in age :  0\n",
      "percentage of upper outliers in age :  0.0 %\n",
      "percentage of lower outliers in age :  0.0 %\n"
     ]
    }
   ],
   "source": [
    "upper_age=df[df['age']>70.5]['age'].count()\n",
    "lower_age=df[df['age']<-10.5]['age'].count()\n",
    "print('number of upper outliers in age : ', upper_age )\n",
    "print('number of lower outliers in age : ', lower_age )\n",
    "print('percentage of upper outliers in age : ', upper_age*100/len(df),'%')\n",
    "print('percentage of lower outliers in age : ', lower_age*100/len(df),'%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c191cbee48>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(df.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.campaign.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.distplot(df.campaign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f['campaign'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"lower outlier in age\",l_out_camp)\n",
    "#print(\"upper outlier in age\",u_out_camp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in df.campaign:\n",
    "   # if i>u_out_camp:\n",
    "      #  df.replace(i,df['campaign'].median(),inplace=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upper_cam=df[df['campaign']>6.0]['campaign'].count()\n",
    "#lower_cam=df[df['campaign']<-2.0]['campaign'].count()\n",
    "#print('number of upper outliers in campaign : ', upper_cam )\n",
    "#print('number of lower outliers in campaign : ', lower_cam )\n",
    "#print('percentage of upper outliers in campaign : ', upper_cam*100/len(df),'%')\n",
    "#print('percentage of lower outliers in campaign : ', lower_cam*100/len(df),'%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.boxplot(df.campaign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45211, 17)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df.job=le.fit_transform(df.job)\n",
    "df.marital=le.fit_transform(df.marital)\n",
    "df.education=le.fit_transform(df.education)\n",
    "df.default=le.fit_transform(df.default)\n",
    "df.housing=le.fit_transform(df.housing)\n",
    "df.loan=le.fit_transform(df.loan)\n",
    "df.contact=le.fit_transform(df.contact)\n",
    "df.month=le.fit_transform(df.month)\n",
    "df.y=le.fit_transform(df.y)\n",
    "df.poutcome=le.fit_transform(df.poutcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1506</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job  marital  education  default  balance  housing  loan  contact  \\\n",
       "0   58    4        1          2        0     2143        1     0        2   \n",
       "1   44    9        2          1        0       29        1     0        2   \n",
       "2   33    2        1          1        0        2        1     1        2   \n",
       "3   47    1        1          3        0     1506        1     0        2   \n",
       "4   33   11        2          3        0        1        0     0        2   \n",
       "\n",
       "   day  month  duration  campaign  pdays  previous  poutcome  y  \n",
       "0    5      8       261         1     -1         0         3  0  \n",
       "1    5      8       151         1     -1         0         3  0  \n",
       "2    5      8        39         1     -1         0         3  0  \n",
       "3    5      8        39         1     -1         0         3  0  \n",
       "4    5      8       198         1     -1         0         3  0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,:-1]\n",
    "y= df.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split( x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler= MinMaxScaler()\n",
    "x_train=scaler.fit_transform(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Classes Counter({0: 26747, 1: 3544})\n",
      "SMOTE Classes Counter({0: 26747, 1: 26747})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "\n",
    "x_train_smote, y_train_smote = smote.fit_resample(x_train.astype('float'),y_train)\n",
    "from collections import Counter\n",
    "print(\"Actual Classes\",Counter(y_train))\n",
    "print(\"SMOTE Classes\",Counter(y_train_smote))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(x_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01276957 0.04261902 0.01596833 0.04170095 0.01198853 0.02115223\n",
      " 0.09950285 0.03292196 0.17173749 0.02730771 0.0724408  0.12561576\n",
      " 0.075156   0.0157247  0.12131164 0.11208241]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model.feature_importances_)\n",
    "pyplot.bar(range(len(model.feature_importances_)), model.feature_importances_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>contact</th>\n",
       "      <td>0.171737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>0.125616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>previous</th>\n",
       "      <td>0.121312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poutcome</th>\n",
       "      <td>0.112082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing</th>\n",
       "      <td>0.099503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign</th>\n",
       "      <td>0.075156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>0.072441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job</th>\n",
       "      <td>0.042619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>0.041701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan</th>\n",
       "      <td>0.032922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>0.027308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance</th>\n",
       "      <td>0.021152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital</th>\n",
       "      <td>0.015968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pdays</th>\n",
       "      <td>0.015725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.012770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>0.011989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature_importance\n",
       "contact              0.171737\n",
       "duration             0.125616\n",
       "previous             0.121312\n",
       "poutcome             0.112082\n",
       "housing              0.099503\n",
       "campaign             0.075156\n",
       "month                0.072441\n",
       "job                  0.042619\n",
       "education            0.041701\n",
       "loan                 0.032922\n",
       "day                  0.027308\n",
       "balance              0.021152\n",
       "marital              0.015968\n",
       "pdays                0.015725\n",
       "age                  0.012770\n",
       "default              0.011989"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data  = pd.DataFrame(data = model.feature_importances_ ,columns=['feature_importance'] ,index=['age','job','marital','education','default','balance','housing','loan','contact','day','month','duration','campaign','pdays','previous','poutcome'])\n",
    "\n",
    "data.sort_values(by='feature_importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model using selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1506</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job  marital  education  default  balance  housing  loan  contact  \\\n",
       "0   58    4        1          2        0     2143        1     0        2   \n",
       "1   44    9        2          1        0       29        1     0        2   \n",
       "2   33    2        1          1        0        2        1     1        2   \n",
       "3   47    1        1          3        0     1506        1     0        2   \n",
       "4   33   11        2          3        0        1        0     0        2   \n",
       "\n",
       "   day  month  duration  campaign  pdays  previous  poutcome  y  \n",
       "0    5      8       261         1     -1         0         3  0  \n",
       "1    5      8       151         1     -1         0         3  0  \n",
       "2    5      8        39         1     -1         0         3  0  \n",
       "3    5      8        39         1     -1         0         3  0  \n",
       "4    5      8       198         1     -1         0         3  0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop(['age','job','marital','education','default','balance','day','pdays','loan','month'],\n",
    "            axis=1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=data.iloc[:,:-1]\n",
    "y1=data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housing</th>\n",
       "      <th>contact</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45206</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>977</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45207</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>456</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45208</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1127</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45209</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>508</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45210</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>361</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45211 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       housing  contact  duration  campaign  previous  poutcome\n",
       "0            1        2       261         1         0         3\n",
       "1            1        2       151         1         0         3\n",
       "2            1        2        39         1         0         3\n",
       "3            1        2        39         1         0         3\n",
       "4            0        2       198         1         0         3\n",
       "...        ...      ...       ...       ...       ...       ...\n",
       "45206        0        0       977         3         0         3\n",
       "45207        0        0       456         2         0         3\n",
       "45208        0        0      1127         5         3         2\n",
       "45209        0        1       508         4         0         3\n",
       "45210        0        0       361         2        11         1\n",
       "\n",
       "[45211 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split( x1, y1, test_size=0.30, random_state=42,stratify=y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler= MinMaxScaler()\n",
    "x_train=scaler.fit_transform(x_train)\n",
    "x_test=scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Classes Counter({0: 27945, 1: 3702})\n",
      "SMOTE Classes Counter({0: 27945, 1: 27945})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "\n",
    "x_train_smote, y_train_smote = smote.fit_resample(x_train.astype('float'),y_train)\n",
    "from collections import Counter\n",
    "print(\"Actual Classes\",Counter(y_train))\n",
    "print(\"SMOTE Classes\",Counter(y_train_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(x_train_smote,y_train_smote)\n",
    "ls_predictions = logmodel.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7952668829253907\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(accuracy_score(y_test,ls_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy of untuned logistic regression with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dismodel = DecisionTreeClassifier()\n",
    "dismodel.fit(x_train_smote,y_train_smote)\n",
    "dis_prediction = dismodel.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8460631082276615\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,dis_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy of untuned decision tree with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfmodel= RandomForestClassifier()\n",
    "rfmodel.fit(x_train_smote,y_train_smote)\n",
    "rfpredict=rfmodel.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8460631082276615\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,rfpredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy of untuned Random forest with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knnmodel=KNeighborsClassifier()\n",
    "knnmodel.fit(x_train_smote,y_train_smote)\n",
    "knnpredict=knnmodel.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8252727808905927\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,knnpredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy of untuned knn classifier with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:02:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "model.fit(x_train_smote,y_train_smote)\n",
    "xgbpredict=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8273370687112946\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,xgbpredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy of untuned XGBoost with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svmmodel=svm.SVC()\n",
    "svmmodel.fit(x_train_smote,y_train_smote)\n",
    "svmpredict=svmmodel.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8164995576526098\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,svmpredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy of untuned SVM with selected features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here best performance is shown by decision tree and random forest classifier\n",
    "we will perform tuning on both to check for more accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 648 candidates, totalling 6480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abc\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.72249061 0.72249061 0.72249061 0.72249061 0.72249061\n",
      " 0.72249061 0.72249061 0.72249061        nan 0.72249061 0.72249061\n",
      " 0.72249061 0.72249061 0.72249061 0.72249061 0.72249061 0.72249061\n",
      "        nan 0.72249061 0.72249061 0.72249061 0.72249061 0.72249061\n",
      " 0.72249061 0.72249061 0.72249061        nan 0.72249061 0.72249061\n",
      " 0.72249061 0.72249061 0.72249061 0.72249061 0.72249061 0.72249061\n",
      "        nan 0.72249061 0.72249061 0.72249061 0.72249061 0.72249061\n",
      " 0.72249061 0.72249061 0.72249061        nan 0.72249061 0.72249061\n",
      " 0.72249061 0.72249061 0.72249061 0.72249061 0.72249061 0.72249061\n",
      "        nan 0.72249061 0.72249061 0.72249061 0.72249061 0.72249061\n",
      " 0.72249061 0.72249061 0.72249061        nan 0.72249061 0.72249061\n",
      " 0.72249061 0.72249061 0.72249061 0.72249061 0.72249061 0.72249061\n",
      "        nan 0.76876006 0.76876006 0.76876006 0.76876006 0.76876006\n",
      " 0.76876006 0.76876006 0.76876006        nan 0.76876006 0.76876006\n",
      " 0.76876006 0.76876006 0.76876006 0.76876006 0.76876006 0.76876006\n",
      "        nan 0.76876006 0.76876006 0.76876006 0.76876006 0.76876006\n",
      " 0.76876006 0.76876006 0.76876006        nan 0.76876006 0.76876006\n",
      " 0.76876006 0.76876006 0.76876006 0.76876006 0.76876006 0.76876006\n",
      "        nan 0.78500626 0.78500626 0.78500626 0.78500626 0.78500626\n",
      " 0.78500626 0.78500626 0.78500626        nan 0.78500626 0.78500626\n",
      " 0.78500626 0.78500626 0.78500626 0.78500626 0.78500626 0.78500626\n",
      "        nan 0.78500626 0.78500626 0.78500626 0.78500626 0.78500626\n",
      " 0.78500626 0.78500626 0.78500626        nan 0.78500626 0.78500626\n",
      " 0.78500626 0.78500626 0.78500626 0.78500626 0.78500626 0.78500626\n",
      "        nan 0.80297012 0.80297012 0.80293434 0.80293434 0.80293434\n",
      " 0.80293434 0.80297012 0.80297012        nan 0.80297012 0.80293434\n",
      " 0.80293434 0.80297012 0.80297012 0.80293434 0.80293434 0.80293434\n",
      "        nan 0.80293434 0.80297012 0.80297012 0.80297012 0.80293434\n",
      " 0.80297012 0.80297012 0.80297012        nan 0.80298801 0.80298801\n",
      " 0.80295223 0.80298801 0.80298801 0.80298801 0.80295223 0.80298801\n",
      "        nan 0.8127572  0.8127572  0.81268563 0.81268563 0.8127572\n",
      " 0.81268563 0.81268563 0.81270352        nan 0.81272142 0.81263196\n",
      " 0.81273931 0.81264985 0.81264985 0.81266774 0.81264985 0.81272142\n",
      "        nan 0.81272142 0.81264985 0.81272142 0.81272142 0.81264985\n",
      " 0.81264985 0.81272142 0.81272142        nan 0.8127572  0.8127572\n",
      " 0.8127572  0.81268563 0.81268563 0.8127572  0.81268563 0.8127572\n",
      "        nan 0.81676507 0.81681875 0.81678297 0.81683664 0.81680086\n",
      " 0.81680086 0.81687243 0.81685454        nan 0.81683664 0.81687243\n",
      " 0.81687243 0.81683664 0.81685454 0.81680086 0.81689032 0.81687243\n",
      "        nan 0.81690821 0.816944   0.81690821 0.816944   0.816944\n",
      " 0.81690821 0.8169261  0.81696189        nan 0.81681875 0.81685454\n",
      " 0.81681875 0.81683664 0.81683664 0.81685454 0.81681875 0.81685454\n",
      "        nan 0.82080873 0.82084452 0.82080873 0.82082662 0.82075505\n",
      " 0.82079084 0.82095187 0.82082662        nan 0.82077295 0.82075505\n",
      " 0.82073716 0.82086241 0.82082662 0.82073716 0.82079084 0.82080873\n",
      "        nan 0.82095187 0.82077295 0.82089819 0.82079084 0.82080873\n",
      " 0.82075505 0.82093398 0.82075505        nan 0.82066559 0.82066559\n",
      " 0.82079084 0.82066559 0.82077295 0.8206477  0.82066559 0.82079084\n",
      "        nan 0.82438719 0.82440508 0.82447665 0.82442297 0.82431562\n",
      " 0.82445876 0.82447665 0.82447665        nan 0.8243693  0.82433351\n",
      " 0.82440508 0.82426194 0.82415459 0.82427984 0.82419037 0.82431562\n",
      "        nan 0.82449454 0.82431562 0.82445876 0.82449454 0.82451244\n",
      " 0.82433351 0.82431562 0.82442297        nan 0.82415459 0.82408302\n",
      " 0.82404724 0.82397567 0.82415459 0.82408302 0.8241367  0.82410091\n",
      "        nan 0.71996779 0.71996779 0.71996779 0.71996779 0.71996779\n",
      " 0.71996779 0.71996779 0.71996779        nan 0.71996779 0.71996779\n",
      " 0.71996779 0.71996779 0.71996779 0.71996779 0.71996779 0.71996779\n",
      "        nan 0.71996779 0.71996779 0.71996779 0.71996779 0.71996779\n",
      " 0.71996779 0.71996779 0.71996779        nan 0.71996779 0.71996779\n",
      " 0.71996779 0.71996779 0.71996779 0.71996779 0.71996779 0.71996779\n",
      "        nan 0.71996779 0.71996779 0.71996779 0.71996779 0.71996779\n",
      " 0.71996779 0.71996779 0.71996779        nan 0.71996779 0.71996779\n",
      " 0.71996779 0.71996779 0.71996779 0.71996779 0.71996779 0.71996779\n",
      "        nan 0.71996779 0.71996779 0.71996779 0.71996779 0.71996779\n",
      " 0.71996779 0.71996779 0.71996779        nan 0.71996779 0.71996779\n",
      " 0.71996779 0.71996779 0.71996779 0.71996779 0.71996779 0.71996779\n",
      "        nan 0.76246198 0.76246198 0.76246198 0.76246198 0.76246198\n",
      " 0.76246198 0.76246198 0.76246198        nan 0.76246198 0.76246198\n",
      " 0.76246198 0.76246198 0.76246198 0.76246198 0.76246198 0.76246198\n",
      "        nan 0.76246198 0.76246198 0.76246198 0.76246198 0.76246198\n",
      " 0.76246198 0.76246198 0.76246198        nan 0.76246198 0.76246198\n",
      " 0.76246198 0.76246198 0.76246198 0.76246198 0.76246198 0.76246198\n",
      "        nan 0.7737878  0.7737878  0.7737878  0.7737878  0.7737878\n",
      " 0.7737878  0.7737878  0.7737878         nan 0.7737878  0.7737878\n",
      " 0.7737878  0.7737878  0.7737878  0.7737878  0.7737878  0.7737878\n",
      "        nan 0.7737878  0.7737878  0.7737878  0.7737878  0.7737878\n",
      " 0.7737878  0.7737878  0.7737878         nan 0.7737878  0.7737878\n",
      " 0.7737878  0.7737878  0.7737878  0.7737878  0.7737878  0.7737878\n",
      "        nan 0.80050098 0.80050098 0.80050098 0.80053677 0.80053677\n",
      " 0.80053677 0.80050098 0.80053677        nan 0.80050098 0.80053677\n",
      " 0.80050098 0.80053677 0.80053677 0.80050098 0.80053677 0.80050098\n",
      "        nan 0.80050098 0.80053677 0.80050098 0.80050098 0.80053677\n",
      " 0.80053677 0.80050098 0.80053677        nan 0.80050098 0.80050098\n",
      " 0.80053677 0.80050098 0.80053677 0.80053677 0.80053677 0.80050098\n",
      "        nan 0.81032385 0.81028807 0.81028807 0.81028807 0.81032385\n",
      " 0.81032385 0.81032385 0.81028807        nan 0.81028807 0.81028807\n",
      " 0.81032385 0.81032385 0.81032385 0.81028807 0.81028807 0.81028807\n",
      "        nan 0.81032385 0.81028807 0.81028807 0.81028807 0.81028807\n",
      " 0.81032385 0.81032385 0.81028807        nan 0.81032385 0.81028807\n",
      " 0.81032385 0.81032385 0.81032385 0.81032385 0.81028807 0.81028807\n",
      "        nan 0.81569154 0.81567364 0.81567364 0.81572732 0.81569154\n",
      " 0.81569154 0.81569154 0.81567364        nan 0.81567364 0.81567364\n",
      " 0.81569154 0.81565575 0.81567364 0.81567364 0.81565575 0.81569154\n",
      "        nan 0.81572732 0.81572732 0.81576311 0.81574521 0.81574521\n",
      " 0.81576311 0.81576311 0.81576311        nan 0.81572732 0.81569154\n",
      " 0.81567364 0.81569154 0.81567364 0.81570943 0.81569154 0.81572732\n",
      "        nan 0.82118447 0.82120236 0.82120236 0.82123815 0.82123815\n",
      " 0.82122025 0.82120236 0.82120236        nan 0.82118447 0.82116658\n",
      " 0.82118447 0.82118447 0.82118447 0.82116658 0.82114868 0.82114868\n",
      "        nan 0.82114868 0.82118447 0.82116658 0.82113079 0.82114868\n",
      " 0.82118447 0.82114868 0.82120236        nan 0.82122025 0.82122025\n",
      " 0.82118447 0.82118447 0.82118447 0.82118447 0.82118447 0.82118447\n",
      "        nan 0.82188227 0.82179281 0.82184648 0.82184648 0.82173913\n",
      " 0.82172124 0.82182859 0.82177492        nan 0.82172124 0.82173913\n",
      " 0.82177492 0.82182859 0.82182859 0.82172124 0.82170335 0.82170335\n",
      "        nan 0.8218107  0.82182859 0.82193595 0.82191805 0.82190016\n",
      " 0.8218107  0.8218107  0.82184648        nan 0.8215781  0.82150653\n",
      " 0.82152442 0.82156021 0.82152442 0.82159599 0.82154232 0.82159599]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': range(1, 10),\n",
       "                         'min_samples_leaf': range(1, 5),\n",
       "                         'min_samples_split': range(1, 10)},\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dismodel = DecisionTreeClassifier()\n",
    "param_dict = {\n",
    "    'criterion': ['gini','entropy'],\n",
    "    'max_depth': (range (1,10)),\n",
    "    'min_samples_split' : (range(1,10)),\n",
    "    'min_samples_leaf'  : (range(1,5))\n",
    "}\n",
    "\n",
    "grid =  GridSearchCV(dismodel,param_grid=param_dict,cv=10,verbose=10,n_jobs=-1)\n",
    "grid.fit(x_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 9,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 6}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79438218814509\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dismodel = DecisionTreeClassifier(criterion = 'gini',\n",
    "    max_depth = 9,\n",
    "    min_samples_split =3 ,\n",
    "    min_samples_leaf  = 6 )\n",
    "dismodel.fit(x_train_smote,y_train_smote)\n",
    "dis_prediction = dismodel.predict(x_test)\n",
    "print(accuracy_score(y_test,dis_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " accuracy of tuned decision tree for selected features \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "accuracy of untuned decision tree is better than tuned model of decision tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.79      0.87     11977\n",
      "           1       0.34      0.81      0.48      1587\n",
      "\n",
      "    accuracy                           0.79     13564\n",
      "   macro avg       0.66      0.80      0.68     13564\n",
      "weighted avg       0.90      0.79      0.83     13564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, dis_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfmodel= RandomForestClassifier()\n",
    "n_estimators = [10, 100, 1000]\n",
    "max_features = ['sqrt', 'log2']\n",
    "\n",
    "grid = dict(n_estimators=n_estimators,max_features=max_features)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rfmodel, param_grid=grid, n_jobs=-1, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(x_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'sqrt', 'n_estimators': 1000}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8473901503981126\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfmodel= RandomForestClassifier(max_features= 'sqrt', n_estimators = 100)\n",
    "rfmodel.fit(x_train_smote,y_train_smote)\n",
    "rfpredict=rfmodel.predict(x_test)\n",
    "print(accuracy_score(y_test,rfpredict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tuned accuracy of random forest with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91     11977\n",
      "           1       0.38      0.52      0.44      1587\n",
      "\n",
      "    accuracy                           0.84     13564\n",
      "   macro avg       0.66      0.70      0.67     13564\n",
      "weighted avg       0.87      0.84      0.85     13564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, rfpredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are getting a good average accuracy but performece for class yes of dependent feature  is not good\n",
    "\n",
    "lets train our model with all feature rather than just selected and compute performece "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training using all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1506</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job  marital  education  default  balance  housing  loan  contact  \\\n",
       "0   58    4        1          2        0     2143        1     0        2   \n",
       "1   44    9        2          1        0       29        1     0        2   \n",
       "2   33    2        1          1        0        2        1     1        2   \n",
       "3   47    1        1          3        0     1506        1     0        2   \n",
       "4   33   11        2          3        0        1        0     0        2   \n",
       "\n",
       "   day  month  duration  campaign  pdays  previous  poutcome  y  \n",
       "0    5      8       261         1     -1         0         3  0  \n",
       "1    5      8       151         1     -1         0         3  0  \n",
       "2    5      8        39         1     -1         0         3  0  \n",
       "3    5      8        39         1     -1         0         3  0  \n",
       "4    5      8       198         1     -1         0         3  0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2=df.iloc[:,:-1]\n",
    "y2= df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train_all, x_test_all, y_train_all, y_test_all = train_test_split( x2, y2, test_size=0.30, random_state=42,stratify=y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler= MinMaxScaler()\n",
    "x_train_all=scaler.fit_transform(x_train_all)\n",
    "x_test_all=scaler.transform(x_test_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Classes Counter({0: 27945, 1: 3702})\n",
      "SMOTE Classes Counter({0: 27945, 1: 27945})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "\n",
    "x_train_smote2, y_train_smote2 = smote.fit_resample(x_train_all.astype('float'),y_train_all)\n",
    "from collections import Counter\n",
    "print(\"Actual Classes\",Counter(y_train_all))\n",
    "print(\"SMOTE Classes\",Counter(y_train_smote2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8095694485402536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(x_train_smote2,y_train_smote2)\n",
    "ls_predictions2 = logmodel.predict(x_test_all)\n",
    "print(accuracy_score(y_test_all,ls_predictions2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy of untuned Logistic Regression model with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8552049542907697\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dismodel = DecisionTreeClassifier()\n",
    "dismodel.fit(x_train_smote2,y_train_smote2)\n",
    "dis_prediction = dismodel.predict(x_test_all)\n",
    "\n",
    "print(accuracy_score(y_test_all,dis_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy of untuned Decision tree model with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8923621350634031\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfmodel= RandomForestClassifier()\n",
    "rfmodel.fit(x_train_smote2,y_train_smote2)\n",
    "rfpredict=rfmodel.predict(x_test_all)\n",
    "print(accuracy_score(y_test_all,rfpredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy of untuned Random Forest model with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8163521085225597\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knnmodel=KNeighborsClassifier()\n",
    "knnmodel.fit(x_train_smote2,y_train_smote2)\n",
    "knnpredict=knnmodel.predict(x_test_all)\n",
    "\n",
    "print(accuracy_score(y_test_all,knnpredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy of untuned KNN model with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abc\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:45:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.8163521085225597\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "model.fit(x_train_smote2,y_train_smote2)\n",
    "xgbpredict=model.predict(x_test_all)\n",
    "print(accuracy_score(y_test_all,knnpredict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy of untuned XGBoost model with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8265260984960189\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svmmodel=svm.SVC()\n",
    "svmmodel.fit(x_train_smote2,y_train_smote2)\n",
    "svmpredict=svmmodel.predict(x_test_all)\n",
    "print(accuracy_score(y_test_all,svmpredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy of untuned SVM model with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best performance with all features is shown by random forest \n",
    "\n",
    "we are going to perform tuning on random forest model too see if we get more accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfmodel= RandomForestClassifier()\n",
    "n_estimators = [10, 100, 1000]\n",
    "max_features = ['sqrt', 'log2']\n",
    "\n",
    "grid = dict(n_estimators=n_estimators,max_features=max_features)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rfmodel, param_grid=grid, n_jobs=-1, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(x_train_smote2, y_train_smote2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9414564322776883"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'sqrt', 'n_estimators': 1000}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8930256561486287\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfmodel= RandomForestClassifier(max_features= 'sqrt', n_estimators = 1000)\n",
    "rfmodel.fit(x_train_smote2,y_train_smote2)\n",
    "rfpredict=rfmodel.predict(x_test_all)\n",
    "print(accuracy_score(y_test_all,rfpredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     11977\n",
      "           1       0.54      0.65      0.59      1587\n",
      "\n",
      "    accuracy                           0.89     13564\n",
      "   macro avg       0.74      0.79      0.76     13564\n",
      "weighted avg       0.90      0.89      0.90     13564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_all, rfpredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most acurate prediction of bank marketing data set is provided by tuned Random Forest with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
